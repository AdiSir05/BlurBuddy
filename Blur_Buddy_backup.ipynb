{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Identification Model for Video Privacy System\n",
    "\n",
    "This notebook implements a machine learning model for identifying faces in videos as part of an adaptive face-blur privacy system.\n",
    "\n",
    "## Overview\n",
    "- Uses face images and landmarks from YouTube dataset\n",
    "- Trains a neural network to identify faces consistently\n",
    "- Provides inference capabilities for video frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cccd7a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/adityasirohi/anaconda3/envs/CIS5810_hw2/lib/python3.10/site-packages (2.8.0)\n",
      "Requirement already satisfied: torchvision in /Users/adityasirohi/anaconda3/envs/CIS5810_hw2/lib/python3.10/site-packages (0.23.0)\n",
      "Requirement already satisfied: torchaudio in /Users/adityasirohi/anaconda3/envs/CIS5810_hw2/lib/python3.10/site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in /Users/adityasirohi/anaconda3/envs/CIS5810_hw2/lib/python3.10/site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/adityasirohi/anaconda3/envs/CIS5810_hw2/lib/python3.10/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/adityasirohi/anaconda3/envs/CIS5810_hw2/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/adityasirohi/anaconda3/envs/CIS5810_hw2/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/adityasirohi/anaconda3/envs/CIS5810_hw2/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/adityasirohi/anaconda3/envs/CIS5810_hw2/lib/python3.10/site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: numpy in /Users/adityasirohi/anaconda3/envs/CIS5810_hw2/lib/python3.10/site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/adityasirohi/anaconda3/envs/CIS5810_hw2/lib/python3.10/site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/adityasirohi/anaconda3/envs/CIS5810_hw2/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/adityasirohi/anaconda3/envs/CIS5810_hw2/lib/python3.10/site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: pandas in /Users/adityasirohi/anaconda3/envs/CIS5810_hw2/lib/python3.10/site-packages (2.3.3)\n",
      "Requirement already satisfied: scikit-learn in /Users/adityasirohi/anaconda3/envs/CIS5810_hw2/lib/python3.10/site-packages (1.7.2)\n",
      "Requirement already satisfied: matplotlib in /Users/adityasirohi/anaconda3/envs/CIS5810_hw2/lib/python3.10/site-packages (3.10.6)\n",
      "Requirement already satisfied: pillow in /Users/adityasirohi/anaconda3/envs/CIS5810_hw2/lib/python3.10/site-packages (11.3.0)\n",
      "Requirement already satisfied: opencv-python in /Users/adityasirohi/anaconda3/envs/CIS5810_hw2/lib/python3.10/site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy in /Users/adityasirohi/anaconda3/envs/CIS5810_hw2/lib/python3.10/site-packages (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/adityasirohi/anaconda3/envs/CIS5810_hw2/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/adityasirohi/anaconda3/envs/CIS5810_hw2/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/adityasirohi/anaconda3/envs/CIS5810_hw2/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Users/adityasirohi/anaconda3/envs/CIS5810_hw2/lib/python3.10/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/adityasirohi/anaconda3/envs/CIS5810_hw2/lib/python3.10/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/adityasirohi/anaconda3/envs/CIS5810_hw2/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/adityasirohi/anaconda3/envs/CIS5810_hw2/lib/python3.10/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/adityasirohi/anaconda3/envs/CIS5810_hw2/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/adityasirohi/anaconda3/envs/CIS5810_hw2/lib/python3.10/site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/adityasirohi/anaconda3/envs/CIS5810_hw2/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/adityasirohi/anaconda3/envs/CIS5810_hw2/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/adityasirohi/anaconda3/envs/CIS5810_hw2/lib/python3.10/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/adityasirohi/anaconda3/envs/CIS5810_hw2/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Installation complete!\n"
     ]
    }
   ],
   "source": [
    "# Load and explore dataset from .npz files",
    "import os",
    "import glob",
    "",
    "# Define data directories",
    "data_base_dir = \"/Users/adityasirohi/BlurBuddy/Data\"",
    "subdirs = [",
    "    \"youtube_faces_with_keypoints_full_1/youtube_faces_with_keypoints_full_1\",",
    "    \"youtube_faces_with_keypoints_full_2/youtube_faces_with_keypoints_full_2\", ",
    "    \"youtube_faces_with_keypoints_full_3/youtube_faces_with_keypoints_full_3\",",
    "    \"youtube_faces_with_keypoints_full_4/youtube_faces_with_keypoints_full_4\"",
    "]",
    "",
    "# Find all .npz files",
    "npz_files = []",
    "for subdir in subdirs:",
    "    subdir_path = os.path.join(data_base_dir, subdir)",
    "    files = glob.glob(os.path.join(subdir_path, \"*.npz\"))",
    "    npz_files.extend(files)",
    "",
    "print(f\"Found {len(npz_files)} .npz files\")",
    "",
    "# Extract person names from filenames",
    "person_names = []",
    "for file_path in npz_files:",
    "    filename = os.path.basename(file_path)",
    "    # Extract person name (everything before the last underscore and number)",
    "    person_name = '_'.join(filename.split('_')[:-1])",
    "    person_names.append(person_name)",
    "",
    "# Create a simple DataFrame-like structure",
    "import pandas as pd",
    "data_info = pd.DataFrame({",
    "    'file_path': npz_files,",
    "    'person_name': person_names",
    "})",
    "",
    "print(f\"Dataset shape: {data_info.shape}\")",
    "print(f\"Unique persons: {data_info['person_name'].nunique()}\")",
    "",
    "# Show top persons by sample count",
    "person_counts = data_info['person_name'].value_counts()",
    "print(f\"",
    "Top 10 persons by sample count:\")",
    "print(person_counts.head(10))",
    "",
    "# Show data distribution",
    "print(f\"",
    "Dataset Info:\")",
    "print(f\"- Total samples: {len(data_info)}\")",
    "print(f\"- Unique persons: {data_info['person_name'].nunique()}\")",
    "print(f\"- Avg samples per person: {len(data_info) / data_info['person_name'].nunique():.1f}\")",
    "print(f\"- Persons with >= 4 samples: {(person_counts >= 4).sum()}\")",
    "",
    "# Store for later use",
    "df = data_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc246495",
   "metadata": {},
   "source": [
    "# Filter dataset - requiring more samples for proper stratification",
    "person_counts = df['person_name'].value_counts()",
    "df_filtered = df[df['person_name'].isin(person_counts[person_counts >= 6].index)]",
    "",
    "print(f\"Filtered dataset: {len(df_filtered)} samples from {df_filtered['person_name'].nunique()} persons\")",
    "",
    "# Split dataset - use simple random split instead of stratification to avoid class imbalance issues",
    "train_df, temp_df = train_test_split(df_filtered, test_size=0.3, random_state=42)",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)",
    "",
    "print(f\"Train set: {len(train_df)} samples\")",
    "print(f\"Validation set: {len(val_df)} samples\")",
    "print(f\"Test set: {len(test_df)} samples\")",
    "",
    "# Create datasets",
    "data_dir = \"/Users/adityasirohi/BlurBuddy/Data\"",
    "train_dataset = FaceDataset(train_df, data_dir)",
    "val_dataset = FaceDataset(val_df, data_dir)",
    "test_dataset = FaceDataset(test_df, data_dir)",
    "",
    "# Test loading a sample",
    "sample_image, sample_landmarks, sample_label = train_dataset[0]",
    "print(f\"",
    "Sample data shapes:\")",
    "print(f\"- Image: {sample_image.shape}\")",
    "print(f\"- Landmarks: {sample_landmarks.shape}\")",
    "print(f\"- Label: {sample_label.item()}\")",
    "",
    "# Get person name",
    "person_name = train_dataset.get_label_encoder().inverse_transform([sample_label.item()])[0]",
    "print(f\"- Person: {person_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4090918f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import our custom model\n",
    "from face_identification_model import *\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3288354",
   "metadata": {},
   "source": [
    "## Step 3: Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3569c2a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string: unmatched '[' (4291465703.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[12], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f\"Unique persons: {df[\"personName\"].nunique()}\")\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m f-string: unmatched '['\n"
     ]
    }
   ],
   "source": [
    "# Load dataset and explore\n",
    "df = pd.read_csv(\"/Users/adityasirohi/BlurBuddy/Data/youtube_faces_with_keypoints_full.csv\")\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Unique persons: {df[\"personName\"].nunique()}\")\n",
    "\n",
    "# Show top persons by sample count\n",
    "person_counts = df[\"personName\"].value_counts()\n",
    "print(f\"\\nTop 10 persons by sample count:\")\n",
    "print(person_counts.head(10))\n",
    "\n",
    "# Show data distribution\n",
    "print(f\"\\nDataset Info:\")\n",
    "print(f\"- Total samples: {len(df)}\")\n",
    "print(f\"- Unique persons: {df[\"personName\"].nunique()}\")\n",
    "print(f\"- Avg samples per person: {len(df) / df[\"personName\"].nunique():.1f}\")\n",
    "print(f\"- Persons with >= 4 samples: {(person_counts >= 4).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162d63d3",
   "metadata": {},
   "source": [
    "## Step 4: Create and Test Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a671561c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter dataset - requiring more samples for proper stratification\n",
    "person_counts = df[\"personName\"].value_counts()\n",
    "df_filtered = df[df[\"personName\"].isin(person_counts[person_counts >= 6].index)]\n",
    "\n",
    "print(f\"Filtered dataset: {len(df_filtered)} samples from {df_filtered[\"personName\"].nunique()} persons\")\n",
    "\n",
    "# Split dataset - use simple random split instead of stratification to avoid class imbalance issues\n",
    "train_df, temp_df = train_test_split(df_filtered, test_size=0.3, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Train set: {len(train_df)} samples\")\n",
    "print(f\"Validation set: {len(val_df)} samples\")\n",
    "print(f\"Test set: {len(test_df)} samples\")\n",
    "\n",
    "# Create datasets\n",
    "data_dir = \"/Users/adityasirohi/BlurBuddy/Data\"\n",
    "train_dataset = FaceDataset(train_df, data_dir)\n",
    "val_dataset = FaceDataset(val_df, data_dir)\n",
    "test_dataset = FaceDataset(test_df, data_dir)\n",
    "\n",
    "# Test loading a sample\n",
    "sample_image, sample_landmarks, sample_label = train_dataset[0]\n",
    "print(f\"\\nSample data shapes:\")\n",
    "print(f\"- Image: {sample_image.shape}\")\n",
    "print(f\"- Landmarks: {sample_landmarks.shape}\")\n",
    "print(f\"- Label: {sample_label.item()}\")\n",
    "\n",
    "# Get person name\n",
    "person_name = train_dataset.get_label_encoder().inverse_transform([sample_label.item()])[0]\n",
    "print(f\"- Person: {person_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990be1e5",
   "metadata": {},
   "source": [
    "## Step 5: Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e306a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "num_classes = train_dataset.get_label_encoder().classes_.shape[0]\n",
    "model = FaceIdentificationModel(num_classes).to(device)\n",
    "\n",
    "print(f\"Model created with {num_classes} classes\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "# Test model with sample data\n",
    "test_image = torch.zeros((1, 3, 64, 64)).to(device)\n",
    "test_landmarks = torch.zeros((1, 136)).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(test_image, test_landmarks)\n",
    "    print(f\"Model output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec2046f",
   "metadata": {},
   "source": [
    "## Step 6: Visualize Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f721d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample faces\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(min(8, len(train_dataset))):\n",
    "    image, landmarks, label_idx = train_dataset[i]\n",
    "    person_name = train_dataset.get_label_encoder().inverse_transform([label_idx.item()])[0]\n",
    "    \n",
    "    # Convert image for display\n",
    "    image_display = image.permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    # Plot images\n",
    "    axes[i].imshow(image_display)\n",
    "    axes[i].set_title(f\"{person_name}\", fontsize=10)\n",
    "    axes[i].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(f\"\\nShown {min(8, len(train_dataset))} sample faces from training set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dad427",
   "metadata": {},
   "source": [
    "## Step 7: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2b50e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize training setup\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \"min\", patience=5, factor=0.5)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"Training setup complete!\")\n",
    "print(f\"Training in {len(train_loader)} batches of {batch_size} samples each\")\n",
    "\n",
    "# Training variables\n",
    "best_val_acc = 0\n",
    "patience = 10\n",
    "no_improve = 0\n",
    "train_losses = []\n",
    "val_accs = []\n",
    "\n",
    "print(\"\\nStarting training...\")\n",
    "print(\"Note: This may take several minutes depending on your hardware\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(20):  # Reduced epochs for demonstration\n",
    "    print(f\"\\nEpoch {epoch + 1}/20:\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Evaluate\n",
    "    val_loss, val_acc, val_preds, val_labels = evaluate(model, val_loader, criterion, device)\n",
    "    val_accs.append(val_acc)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save({\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"val_acc\": val_acc,\n",
    "            \"epoch\": epoch,\n",
    "            \"label_encoder\": train_dataset.get_label_encoder()\n",
    "        }, \"face_identification_model.pth\")\n",
    "        no_improve = 0\n",
    "        print(f\"  -> Best model saved! (Val Acc: {val_acc:.2f}%)\")\n",
    "    else:\n",
    "        no_improve += 1\n",
    "    \n",
    "    # Early stopping check\n",
    "    if no_improve >= patience:\n",
    "        print(f\"  -> Early stopping triggered after {epoch + 1} epochs\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nTraining completed! Best validation accuracy: {best_val_acc:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}